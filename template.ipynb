{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1f02dc-751c-4e65-b652-fa8109edb115",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208d1500-212e-4608-9ea4-384360f24949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2ba0f4-07b8-4837-9e08-c463120d3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13648f68-93d3-4258-bdd4-e32ef25fde5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Hidden Markov model with discrete states and observations.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden, n_observed):\n",
    "        \"\"\"\n",
    "        Initialize model with n_hidden states and n_observed states.\n",
    "        \"\"\"\n",
    "        super(HMM, self).__init__()\n",
    "        self.K = n_hidden\n",
    "        self.V = n_observed\n",
    "        self.prior_module = PriorModule(self.K)\n",
    "        self.transition_module = TransitionModule(self.K)\n",
    "        self.emission_module = EmissionModule(self.K, self.V)\n",
    "\n",
    "        # enable cuda is it is available\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432d0dc-0567-40f6-b3d3-50e61cc583d4",
   "metadata": {},
   "source": [
    "### Prior probabilities\n",
    "\n",
    "The prior probability vector $\\boldsymbol{\\alpha}$ is defined as\n",
    "$$\n",
    "\\alpha[k] = P(z_0 = k) .\n",
    "$$\n",
    "\n",
    "Since $P(z_0)$ is probability distribution, it must sum to 1:\n",
    "$$\n",
    "\\sum_{k = 0}^{K - 1} P(z_0 = k) = 1 .\n",
    "$$\n",
    "\n",
    "In order to preserve numerical precision, we store $\\boldsymbol{\\alpha}$ as real values with range from $-\\infty$ to $\\infty$. We name this variable `real_alpha`. Keeping `alpha` in real space also allows us to randomly initialize it using the standard normal distribution.\n",
    "\n",
    "Accordingly, we must normalize `real_alpha` before returning it as the prior probability vector. In other words, we must normalize `real_alpha` such that\n",
    "$$\n",
    "\\sum_{k = 0}^{K - 1} \\alpha[k] = 1 .\n",
    "$$\n",
    "\n",
    "For this, we can use the `torch.nn.functional.softmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df12f49-edc4-4c30-86fe-aecf2b8e3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorModule(torch.nn.Module):\n",
    "    def __init__(self, K):\n",
    "        \"\"\"\n",
    "        Create prior vector with random initial values.\n",
    "        \"\"\"\n",
    "        super(PriorModule, self).__init__()\n",
    "        self.K = K\n",
    "        self.real_alpha = torch.nn.Parameter(torch.randn(K))\n",
    "\n",
    "    def probs(self):\n",
    "        \"\"\"\n",
    "        Return the prior probability vector.\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.softmax(\n",
    "            ???\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac91483-de49-4075-8bda-9e3938241b87",
   "metadata": {},
   "source": [
    "### Transition probabilities\n",
    "\n",
    "The transition probability matrix $\\boldsymbol{B}$ is defined such that\n",
    "$$\n",
    "B[k, l] = P(z_{t+1} = l \\mid z_{t} = k) .\n",
    "$$\n",
    "(Note: As per standard mathematical notation, we represent a matrix by an uppercase bold letter. The uppercase of $\\beta$ is $B$.)\n",
    "\n",
    "The `TransitionModule` will store the transition matrix as real values (i.e. their ranges are from $-\\infty$ to $\\infty$. It will normalize the transition matrix.\n",
    "\n",
    "Therefore, this module needs to normalize the `real_Beta` in order to obtain proper probability values; that is, for each hidden state $i$,\n",
    "$$\n",
    "\\sum_{l = 0}^{K-1} P(z_{t+1} = l \\mid z_{t} = k) = 1 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2547a2-4389-4423-a8e5-1f78bee4228a",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40382080-b383-4fba-8fd4-49d0fc034c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionModule(torch.nn.Module):\n",
    "    def __init__(self, K):\n",
    "        \"\"\"\n",
    "        Create transition matrix with K hidden states and random initial values.\n",
    "        \"\"\"\n",
    "        super(TransitionModule, self).__init__()\n",
    "        self.K = K\n",
    "        # sample initial values from standard normal\n",
    "        self.real_Beta = ???\n",
    "        \n",
    "    def probs(self):\n",
    "        \"\"\"\n",
    "        Return the transition probability matrix.\n",
    "        \"\"\"\n",
    "        return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1e697-9f82-41ac-a8f6-df9eada2c6ed",
   "metadata": {},
   "source": [
    "### Emission probabilities\n",
    "\n",
    "The emission probability matrix $\\boldsymbol{\\Gamma}$ is defined as \n",
    "$$\n",
    "\\Gamma[k, v] = P( x_t = v \\mid z_t = k) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff72edd-e732-47ab-a56b-12d941a7097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmissionModule(torch.nn.Module):\n",
    "    def __init__(self, K, V):\n",
    "        \"\"\"\n",
    "        Randomly initialize emission matirx with K hidden states and V observed states.\n",
    "        \"\"\"\n",
    "        ???\n",
    "\n",
    "    def probs(self):\n",
    "        \"\"\"\n",
    "        Return the emission probability matrix.\n",
    "        \"\"\"\n",
    "        return ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be12a61-c7b5-4835-8606-19cfa3a7fb56",
   "metadata": {},
   "source": [
    "### Sampling from the model\n",
    "\n",
    "Once the parameters $(\\boldsymbol{\\alpha}, \\boldsymbol{B}, \\boldsymbol{\\Gamma})$ are fully specified, we can sample from the HMM simply by following the model definition:\n",
    "\n",
    "For $t = 0$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_0 \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\alpha} ) , \\\\\n",
    "x_0 \\mid z_0 = k \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\gamma}_k ) ,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\boldsymbol{\\gamma}_k$ is the $k$-th row of $\\boldsymbol{\\Gamma}$.\n",
    "\n",
    "For $1 < t < T$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_t \\mid z_{t-1} \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\beta}_k ) , \\\\ \n",
    "x_t \\mid z_t = k \\; &\\sim \\; \\text{Categorical}( \\boldsymbol{\\gamma}_k ) ,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\boldsymbol{\\beta}_k$ is the $k$-th row of $\\boldsymbol{B}$.\n",
    "\n",
    "We can draw a sample from a categorical distribution using `torch.distributions.categorical.Categorical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63b3692-039a-485d-b0a8-b2150a936daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(self, T=10):\n",
    "    \"\"\"\n",
    "    Sample from the hidden Markov model for T time points.\n",
    "    \"\"\"\n",
    "\n",
    "    from torch.distributions.categorical import Categorical\n",
    "\n",
    "    # obtain normalized probabilities\n",
    "    priors = self.prior_module.probs()\n",
    "    transitions = self.transition_module.probs()\n",
    "    emissions = self.emission_module.probs()\n",
    "\n",
    "    # initialize state arrays\n",
    "    z = np.zeros(T, dtype=np.int8)\n",
    "    x = np.zeros(T, dtype=np.int8)\n",
    "    \n",
    "    # sample initial state\n",
    "    z_t = Categorical(priors).sample().item()\n",
    "    z[0] = z_t\n",
    "    \n",
    "    for t in range(0, T):\n",
    "        # sample emission\n",
    "        ???\n",
    "        x[t] = x_t\n",
    "\n",
    "        # sample transition\n",
    "        ???\n",
    "        z[t] = z_t\n",
    "\n",
    "    return x, z\n",
    "\n",
    "# add sampling method to HMM class\n",
    "HMM.sample = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab1c511-8829-49fa-9a81-8cd49d9bbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMM(4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34c2165-317a-4fa5-b9f0-e1da5a9fc0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 5, 5, 3, 3, 3, 1, 5, 1, 5], dtype=int8),\n",
       " array([2, 3, 2, 1, 2, 3, 2, 3, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f3b6d-e2fa-4546-a3be-58217ea3310c",
   "metadata": {},
   "source": [
    "### Learning model parameters\n",
    "\n",
    "You can hard-code HMM parameters to achieve the behaivour that \n",
    "you desire. However, we would typically want to learn the parameters by training our model on data.\n",
    "\n",
    "The PyTorch allows us to minimize a loss function using stochastic gradient descent. Thanks to automatic differentiation, we will not have to analytically derive the gradient equations.\n",
    "\n",
    "All we need to do is to specify and implement a loss function. A sensible objective function is the model evidence $p(\\boldsymbol{x})$ for the observed data $\\boldsymbol{x} = (x_0 \\dots x_{T-1})$.\n",
    "\n",
    "In HMM, the model evidence follows directly from its model specifiction:\n",
    "$$\n",
    "p(\\boldsymbol{x}) \n",
    "= \\sum_{\\boldsymbol{z}} \n",
    "  p( \\boldsymbol{x} \\mid \\boldsymbol{z} ) \\; \n",
    "  p( \\boldsymbol{z} )\n",
    "= \\sum_{\\boldsymbol{z}} \\; p(x_0 \\mid z_0) \\, p( z_0 ) \\; \n",
    "  \\prod_{t > 0} p( x_t \\mid z_t ) \\, p( z_t \\mid z_{t-1} )\n",
    "$$\n",
    "\n",
    "We want to *maximize* the model evidence $p(\\boldsymbol{x})$. To avoid numeric underflow, we can work in log scale such that we maximize $\\log p(\\boldsymbol{x}) $, which is mathematically maximizing $p(\\boldsymbol{x})$. Since in PyTorch, we need to *minimize* a loss function, we can therefore define our loss function as\n",
    "$$\n",
    "L_{\\theta}(\\boldsymbol{x}) = - \\log p_{\\theta}(\\boldsymbol{x}) ,\n",
    "$$\n",
    "where we use $\\theta$ to represent the collection of all model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c0de8-b2bb-4f6b-8a7a-b4dcacbd9024",
   "metadata": {},
   "source": [
    "The model evidence $p(\\boldsymbol{x})$ for HMM can be efficiently calculated using the dynamic programming algorithm, and in HMM, we call this algorithm the **forward algorithm**.\n",
    "\n",
    "The key idea of the forward algorithm is that we can calculate the following probability efficiently:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a_{k, t} \n",
    " &\\triangleq p( x_0, \\ldots, x_t, z_t = k) \\\\\n",
    " &= p( x_t \\mid z_t = k) \\;\n",
    "   \\sum_l \\; \n",
    "    p( z_t = k \\mid z_{t-1} = l ) \\,\n",
    "    p( x_0, \\ldots, x_{t-1}, z_{t-1} = l ) \\\\\n",
    " &= \\boldsymbol{\\gamma}_k \\;\n",
    "   \\sum_l \\;\n",
    "    \\beta_{k, l} \\, a_{l, t-1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "And this recursive equation can be calculated efficient using dynamic programming.\n",
    "\n",
    "After we calculate $a_{k,t}$, we can determine the model evidence by\n",
    "$$\n",
    "p(\\boldsymbol{x}) = \\sum_k a_{k, T}\n",
    "$$\n",
    "\n",
    "Again, in order to avoid numeric underflow, we work in log scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f50c6ed-f332-452e-83c9-8ae28797350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(self, x, T):\n",
    "    \"\"\"\n",
    "    Compute log p(x) for each sample in a batch.\n",
    "    \n",
    "    x: IntTensor of shape (batch_size, T_max)\n",
    "    T: IntTensor of shape (batch_size)\n",
    "    \n",
    "    x[i, :] contains a sample of input whose length is\n",
    "    specified in T[i]. T_max is the maximum sample length \n",
    "    across all samples in a batch.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = x.shape[0]\n",
    "    T_max = x.shape[1]\n",
    "    \n",
    "    log_priors = self.prior_module()\n",
    "    \n",
    "    log_a = torch.zeros(batch_size, T_max, self.K)\n",
    "    log_a[:, 0, :] = self.emission_module(x[:,0]) + log_priors\n",
    "    for t in range(1, T_max):\n",
    "        log_a[:, t, :] = self.emission_module(x[:,t]) + \\\n",
    "            self.transition_module(log_a[:, t-1, :])\n",
    "    \n",
    "    # select the sum for the final time (T - 1)\n",
    "    # (each sample x can have a different T).\n",
    "    log_sums = log_a.logsumexp(dim=2)\n",
    "    log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n",
    "    \n",
    "    return log_probs\n",
    "\n",
    "def prior_module_forward(self):\n",
    "    \"\"\"\n",
    "    Return log prior probability vector.\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.log_softmax(self.real_alpha, dim=0)\n",
    "\n",
    "def transition_module_forward(self, prev_log_a):\n",
    "    \"\"\"\n",
    "    Return log a_{0:(K-1), t} using log a_{0:(K-1), t-1}\n",
    "    \n",
    "    prev_log_a : Tensor of shape (batch_size, K); column k is log_a{k, t-1}\n",
    "    \"\"\"\n",
    "    log_probs = torch.nn.functional.log_softmax(self.real_Beta, dim=1)\n",
    "    log_a = log_matmul(log_probs, prev_log_a.transpose(0,1)).transpose(0,1)\n",
    "    return log_a\n",
    "    \n",
    "def emission_module_forward(self, x_t):\n",
    "    \"\"\"\n",
    "    Return log emission probabilities p( x_t \\mid z_t) for \n",
    "    observation x_t.\n",
    "    \"\"\"\n",
    "    log_probs = torch.nn.functional.log_softmax(self.real_Gamma, dim=1)\n",
    "    return log_probs[:, x_t].transpose(0,1)\n",
    "\n",
    "def log_matmul(log_A, log_B):\n",
    "\t\"\"\"\n",
    "    Compute log(A B) given log A and log B\n",
    " \n",
    "\tlog_A: m x k\n",
    "\tlog_B: k x n\n",
    "\toutput: m x n matrix\n",
    "\n",
    "    For C = A B, we have\n",
    "\tC_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
    "\n",
    "    Here, we compute log C by\n",
    "\tlog C_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
    "\t\"\"\"\n",
    "\tm = log_A.shape[0]\n",
    "\tk = log_A.shape[1]\n",
    "\tn = log_B.shape[1]\n",
    "\n",
    "\tlog_A_expanded = torch.reshape(log_A, (m,k,1))\n",
    "\tlog_B_expanded = torch.reshape(log_B, (1,k,n))\n",
    "\n",
    "\telementwise_sum = log_A_expanded + log_B_expanded\n",
    "\tout = torch.logsumexp(elementwise_sum, dim=1)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "PriorModule.forward = prior_module_forward\n",
    "TransitionModule.forward = transition_module_forward\n",
    "EmissionModule.forward = emission_module_forward\n",
    "HMM.forward = forward_algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49ba1c-85e0-40bd-b22e-8bf41112a712",
   "metadata": {},
   "source": [
    "### Encoding and decoding\n",
    "\n",
    "We will be working with text input, so we need to encode the data appropriately. For HMM, since we only use the encoded values for the purposing of indexing the emission and transition probability matrices, integer encoding is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca0b598-be7a-4dfc-903d-79166fc184df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(xs):\n",
    "    character_set = string.ascii_lowercase\n",
    "    return ???\n",
    "\n",
    "def decode(ys, character_set=string.ascii_lowercase):\n",
    "    character_set = string.ascii_lowercase\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6fa061-7707-4cd3-b998-a250c7cc9853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 3, 3, 4, 13]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47bea11-f618-43d0-b800-a3b3e02cbe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hidden'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(np.array([7, 8, 3, 3, 4, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702c047e-ff02-4aae-857b-5e94453cdc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abefbfefdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model.sample()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed942079-e664-4a60-bf59-4a671ca5440b",
   "metadata": {},
   "source": [
    "### Running forward algorithm\n",
    "\n",
    "With the forward algorithm and the encoder/decoder functions implemented, we are now ready to run the forward algorithm to calculate the log model evidence. This should output a floating value that is usually negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41dd4022-b823-4209-a0a0-ad08d99e7f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7857]], grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n",
    "T = torch.tensor([3])\n",
    "\n",
    "model = HMM(n_hidden=2, n_observed=26)\n",
    "\n",
    "model.forward(x, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbc568-2693-45ef-9c9f-8271b07ff0ae",
   "metadata": {},
   "source": [
    "Now that we have successfully implemented the forward pass in PyTorch, we can take advantage of its automatic differentiation capability to optimize our objective function by stochastic gradient descent. No mathematical derivation needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82487fb8-708d-455c-ba40-b6a5495ed2a7",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad1c3dce-2e39-467a-bfac-b97bd989a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-15 01:40:37--  https://github.com/dwyl/english-words/raw/master/words_alpha.txt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt [following]\n",
      "--2024-04-15 01:40:38--  https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4234917 (4.0M) [text/plain]\n",
      "Saving to: ‘data/words.txt’\n",
      "\n",
      "data/words.txt      100%[===================>]   4.04M  7.51MB/s    in 0.5s    \n",
      "\n",
      "2024-04-15 01:40:38 (7.51 MB/s) - ‘data/words.txt’ saved [4234917/4234917]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!wget -O data/words.txt https://github.com/dwyl/english-words/raw/master/words_alpha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419225c7-6a16-451e-8aa3-a2e7ba9d7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.preprocess as pp\n",
    "reload(pp)\n",
    "\n",
    "in_fname = \"data/words.txt\"\n",
    "\n",
    "with open(in_fname, \"r\") as f:\n",
    "  words_all = [x.rstrip() for x in f.readlines()]\n",
    "\n",
    "# use only words that begin with 'q' in order to reduce training time\n",
    "words = []\n",
    "for word in words_all:\n",
    "    if word[0] == 'q':\n",
    "        words.append(word)\n",
    "\n",
    "# split data into training and testing\n",
    "train_words, valid_words = train_test_split(words, test_size=0.1, random_state=1)\n",
    "train_dataset = pp.TextDataset(train_words, encode)\n",
    "valid_dataset = pp.TextDataset(valid_words, encode)\n",
    "\n",
    "# construct character set\n",
    "character_set = list(pp.Counter((\"\".join(words))).keys())\n",
    "n_observed = len(character_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb1185a5-097f-4cbd-9815-928c95cc068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quixotically',\n",
       " 'quadruplicity',\n",
       " 'quadriplicated',\n",
       " 'quadriplegia',\n",
       " 'quincentenary']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaea7f1e-ef1d-4a39-80a1-6f6e04236877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qual', 'quirite', 'quatorzes', 'quantizable', 'quebracho']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_words[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ada1a7-1f96-4fb6-b1f8-a72ac3f64868",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acf5676a-f71c-4862-bac1-fa485e02a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 1 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▍                                                                | 1/13 [00:00<00:01,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31.002273559570312\n",
      "ocynbnanpf\n",
      "[1 1 0 2 0 2 0 2 0 2]\n",
      "xkjxmxyxqb\n",
      "[2 2 0 2 0 2 0 3 0 2]\n",
      "ubbfuxxfmn\n",
      "[2 2 0 2 0 0 0 0 0 2]\n",
      "ixvxyoufow\n",
      "[3 3 0 2 3 3 3 3 0 0]\n",
      "sxxhppglvf\n",
      "[3 0 2 0 2 2 2 3 3 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 49.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32.7432746887207\n",
      "qxklonveya\n",
      "[3 2 2 0 0 3 1 2 1 1]\n",
      "========= Results: epoch 1 of 10 =========\n",
      "train loss: 31.45| valid loss: 32.59\n",
      "\n",
      "========= Epoch 2 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 76.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30.608352661132812\n",
      "ornfvtgfqf\n",
      "[3 0 2 1 1 1 2 0 0 0]\n",
      "hmnagtqmnq\n",
      "[2 0 0 0 2 0 2 0 0 0]\n",
      "sakgqscffp\n",
      "[0 2 2 0 3 1 2 0 2 0]\n",
      "jfyowgmfhf\n",
      "[2 3 1 0 0 2 2 0 0 0]\n",
      "xnwnwvynro\n",
      "[0 2 0 0 3 2 0 3 3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31.79302215576172\n",
      "dnajqlvxgq\n",
      "[3 0 2 0 0 0 0 0 0 2]\n",
      "========= Results: epoch 2 of 10 =========\n",
      "train loss: 30.21| valid loss: 31.41\n",
      "\n",
      "========= Epoch 3 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28.807350158691406\n",
      "xapgqpgfto\n",
      "[0 0 2 3 1 0 0 0 1 1]\n",
      "fqztwlqifa\n",
      "[0 3 0 2 1 3 2 0 0 1]\n",
      "auhkoxymcg\n",
      "[3 3 3 1 3 3 0 2 1 3]\n",
      "frfxmuecdg\n",
      "[3 3 3 0 0 0 2 0 0 2]\n",
      "qtvyxbpxqq\n",
      "[0 2 2 0 0 0 0 3 3 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30.428682327270508\n",
      "nfbxwpisfm\n",
      "[0 2 0 0 3 3 3 3 0 2]\n",
      "========= Results: epoch 3 of 10 =========\n",
      "train loss: 29.17| valid loss: 30.43\n",
      "\n",
      "========= Epoch 4 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▎                                     | 6/13 [00:00<00:00, 55.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28.061830520629883\n",
      "sfqganuquo\n",
      "[3 0 2 0 0 3 3 3 3 3]\n",
      "dfmiaorjje\n",
      "[0 3 3 3 3 3 2 2 2 0]\n",
      "xxmqlqopzn\n",
      "[0 0 0 0 3 3 0 3 0 0]\n",
      "nzbdvbnagh\n",
      "[2 2 1 3 3 3 3 0 0 0]\n",
      "ifcwgivqiq\n",
      "[3 3 1 1 3 3 3 3 3 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 64.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29.888011932373047\n",
      "iuamzmfpqa\n",
      "[0 0 0 2 0 0 0 3 0 2]\n",
      "========= Results: epoch 4 of 10 =========\n",
      "train loss: 28.31| valid loss: 29.61\n",
      "\n",
      "========= Epoch 5 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 85.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.75005340576172\n",
      "oicisxwiva\n",
      "[3 1 3 0 0 0 0 0 0 3]\n",
      "oannuvoaxy\n",
      "[3 0 0 2 0 0 0 0 2 0]\n",
      "asnvvhmilm\n",
      "[2 0 3 3 3 0 1 1 0 3]\n",
      "fiqqaasaiz\n",
      "[3 3 0 3 1 1 0 3 3 3]\n",
      "puwdbdlmoa\n",
      "[0 1 1 3 1 1 3 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28.887752532958984\n",
      "lyceqbrxnq\n",
      "[2 2 0 0 2 2 1 0 0 2]\n",
      "========= Results: epoch 5 of 10 =========\n",
      "train loss: 27.60| valid loss: 28.93\n",
      "\n",
      "========= Epoch 6 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▏                                                     | 3/13 [00:00<00:00, 28.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25.81454086303711\n",
      "rvvvflddgx\n",
      "[3 3 3 0 2 1 0 2 0 0]\n",
      "njkfaaurql\n",
      "[0 0 0 0 0 3 3 3 0 0]\n",
      "nqiqoiqymm\n",
      "[0 0 3 1 1 0 0 0 3 3]\n",
      "qnsggngamq\n",
      "[0 0 2 2 0 0 0 0 0 3]\n",
      "qkskgnizaa\n",
      "[3 0 0 0 0 2 0 0 3 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 52.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28.199045181274414\n",
      "gfxeaonhiw\n",
      "[0 2 1 0 3 0 2 1 1 3]\n",
      "========= Results: epoch 6 of 10 =========\n",
      "train loss: 27.01| valid loss: 28.36\n",
      "\n",
      "========= Epoch 7 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 75.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.207706451416016\n",
      "qmoqfeikvl\n",
      "[3 3 3 0 0 3 3 2 1 0]\n",
      "zqqnicmnaq\n",
      "[0 0 0 1 0 0 0 0 0 2]\n",
      "ydsomacrti\n",
      "[0 3 3 3 0 3 3 2 0 0]\n",
      "taucambcxw\n",
      "[0 2 2 0 2 0 3 0 0 0]\n",
      "gysxuiofhq\n",
      "[3 3 2 0 3 1 1 3 0 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27.723583221435547\n",
      "opwailqtqo\n",
      "[0 0 0 0 0 0 2 0 3 3]\n",
      "========= Results: epoch 7 of 10 =========\n",
      "train loss: 26.51| valid loss: 27.87\n",
      "\n",
      "========= Epoch 8 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████▋                                | 7/13 [00:00<00:00, 66.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27.191570281982422\n",
      "khoenxkqfq\n",
      "[3 3 3 0 3 3 0 3 3 3]\n",
      "daqrhrparo\n",
      "[0 0 3 3 3 3 3 2 1 3]\n",
      "qibqnukorg\n",
      "[3 3 3 0 0 3 0 3 2 0]\n",
      "aovqvaqiwq\n",
      "[1 1 3 0 0 0 0 2 0 0]\n",
      "rbfvmcsouq\n",
      "[3 0 3 3 1 1 0 3 3 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 75.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27.52946662902832\n",
      "iugenaaabg\n",
      "[0 2 2 0 2 0 1 0 1 1]\n",
      "========= Results: epoch 8 of 10 =========\n",
      "train loss: 26.07| valid loss: 27.43\n",
      "\n",
      "========= Epoch 9 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▏                                                     | 3/13 [00:00<00:00, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.815515518188477\n",
      "nluiqxivqt\n",
      "[0 3 3 3 3 3 0 3 3 0]\n",
      "iafqqhutfn\n",
      "[3 3 0 3 2 2 0 0 0 0]\n",
      "athfqreiux\n",
      "[0 3 3 3 1 0 0 0 0 0]\n",
      "iwkiqanspb\n",
      "[0 3 0 3 0 0 2 0 3 0]\n",
      "faivmaaxuc\n",
      "[3 3 3 0 0 0 2 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 55.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27.388553619384766\n",
      "qpqqclddaa\n",
      "[0 3 3 3 1 1 1 0 0 2]\n",
      "========= Results: epoch 9 of 10 =========\n",
      "train loss: 25.67| valid loss: 27.00\n",
      "\n",
      "========= Epoch 10 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████▌                                                | 4/13 [00:00<00:00, 37.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.252410888671875\n",
      "nuqapiaqxx\n",
      "[3 3 3 0 0 0 3 3 0 0]\n",
      "nenoslcinh\n",
      "[2 0 3 0 0 2 1 0 3 3]\n",
      "uqgaubaapu\n",
      "[3 0 0 0 2 0 0 3 3 0]\n",
      "iwdiquaaqi\n",
      "[0 3 3 3 2 0 0 0 3 0]\n",
      "uenqpidxfq\n",
      "[3 0 0 2 0 2 0 0 3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.315317153930664\n",
      "exkaemepdu\n",
      "[0 1 1 1 1 1 0 0 0 0]\n",
      "========= Results: epoch 10 of 10 =========\n",
      "train loss: 25.24| valid loss: 26.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "reload(train)\n",
    "\n",
    "model = HMM(4, n_observed=n_observed)\n",
    "\n",
    "# number of training passes through the data\n",
    "n_epochs = 10\n",
    "trainer = train.Trainer(model, learning_rate=0.01)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"========= Epoch %d of %d =========\" % (epoch+1, n_epochs))\n",
    "    train_loss = trainer.train(train_dataset, decode)\n",
    "    valid_loss = trainer.test(valid_dataset, decode)\n",
    "\n",
    "    print(\"========= Results: epoch %d of %d =========\" % (epoch+1, n_epochs))\n",
    "    print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65855c-31a3-40d8-b431-09e3adea0820",
   "metadata": {},
   "source": [
    "### Examining the trained model\n",
    "\n",
    "We can examine the trained model by sampling a few words from it. We need to decode the output in order to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27b8a288-ca70-4f14-9128-db7951c46d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: uqoniqqvia , z: [3 3 3 3 3 3 3 3 3 3]\n",
      "x: iaqraranqq , z: [3 3 1 0 3 3 0 0 3 2]\n",
      "x: oqnnaaregz , z: [3 0 0 1 1 1 1 0 0 0]\n",
      "x: qaukroarle , z: [0 2 2 1 1 1 3 0 1 1]\n",
      "x: suuqbqilnu , z: [3 3 3 3 3 3 2 0 3 3]\n",
      "x: qawtcbraco , z: [3 3 3 3 3 3 3 3 3 3]\n",
      "x: quenoqcqno , z: [3 2 0 0 3 3 3 0 3 3]\n",
      "x: vqqxogqfhi , z: [0 0 2 1 3 3 3 3 3 3]\n",
      "x: uqqfvtmuno , z: [3 3 3 0 0 0 3 3 3 0]\n",
      "x: hiqqolrash , z: [3 3 3 3 1 1 0 0 3 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    s = model.sample()\n",
    "    print(\n",
    "        \"x:\", decode(s[0]),\n",
    "        \", z:\", s[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae088f48-e516-46df-a540-ef1188fe23c5",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How do you know whether the training is complete?\n",
    "2. Is it better to have more or fewer hidden states in the HMM? Why?\n",
    "3. How can you improve the model further?\n",
    "\n",
    "### Bonus Questions\n",
    "\n",
    "4. Train a HMM to learn the restriction endonuclease\n",
    "   recognition sequences from [New England Biolabs][1].\n",
    "   You will need to preprocess the data appropriately.\n",
    "\n",
    "5. Implement the Viterbi algorithm.\n",
    "   (Hint: it is very similar to the forward algorithm.)\n",
    "\n",
    "[1]: https://www.neb.com/en/tools-and-resources/selection-charts/alphabetized-list-of-recognition-specificities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bbaad-4140-4f9a-aa59-03aa945bc353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
